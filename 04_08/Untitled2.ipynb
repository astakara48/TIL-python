{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download() # nltk data 다운로드\n",
    "# github.com/nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import konlpy\n",
    "konlpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JPype : 자바와 파이썬 연결\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화, 정제, 정규화\n",
    "# 토큰화 :어절, 단어, 문장, 문단\n",
    "# 단어 토큰화\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'Jone', \"'s\", 'Do', \"n't\", 'be', '!']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(\"Mr. Jone's Don't be!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr', '.', 'Jone', \"'\", 's', 'Don', \"'\", 't', 'be']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "print(WordPunctTokenizer().tokenize(\"Mr. Jone's Don't be\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mr', \"jone's\", \"don't\", 'be']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_word_sequence(\"Mr. Jone's Don't be!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'Jone', \"'s\", 'Do', \"n't\", 'be', '!']\n"
     ]
    }
   ],
   "source": [
    "twt=TreebankWordTokenizer()\n",
    "print(twt.tokenize(\"Mr. Jone's Don't be!\"))\n",
    "\n",
    "# TreebankWordTokenizer, word_tokenize 가 표준으로 가장 많이 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "text=\"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python is an interpreted, high-level, general-purpose programming language.', \"Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\", 'Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(text)) # 토큰의 단위가 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 분석의 문제점 -> 조사\n",
    "# 한국어 토큰화 작업 : 형태소(가장 작은 말의 단위) 고려 필수\n",
    "# 자립 형태소(길동이, 파이썬) / 의존 형태소 (조사, 어미, ...)\n",
    "# ex) 길동이가 파이썬을 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 품사 태깅(tagging), fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'is', 'an', 'interpreted', ',', 'high-level', ',', 'general-purpose', 'programming', 'language', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('interpreted', 'JJ'),\n",
       " (',', ','),\n",
       " ('high-level', 'JJ'),\n",
       " (',', ','),\n",
       " ('general-purpose', 'JJ'),\n",
       " ('programming', 'NN'),\n",
       " ('language', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='Python is an interpreted, high-level, general-purpose programming language.'\n",
    "print(word_tokenize(text))\n",
    "\n",
    "from nltk.tag import pos_tag\n",
    "pos_tag(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 : Okt, Mecab, Kkma...\n",
    "# 단어토큰화가 아님, 형태소 단위로 토큰화를 하는 것\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '은', '수요일', ',', '내일', '은', '목요일', '입니다']\n",
      "[('오늘', 'Noun'), ('은', 'Josa'), ('수요일', 'Noun'), (',', 'Punctuation'), ('내일', 'Noun'), ('은', 'Josa'), ('목요일', 'Noun'), ('입니다', 'Adjective')]\n",
      "['오늘', '수요일', '내일', '목요일']\n"
     ]
    }
   ],
   "source": [
    "okt=Okt()\n",
    "# Okt버전이랑 jpype1 버전이 맞이 않은 경우 에러가 발생함\n",
    "# pip install jpype1==0.7.0 처럼 수정\n",
    "print(okt.morphs(\"오늘은 수요일, 내일은 목요일입니다\")) # 형태소를 추출하는 함수\n",
    "print(okt.pos(\"오늘은 수요일, 내일은 목요일입니다\")) # 품사를 추출하는 함수\n",
    "print(okt.nouns(\"오늘은 수요일, 내일은 목요일입니다\")) # 명사를 추출하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['꾸', '어', '어', '어', '얼']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kma=Kkma()\n",
    "kma.morphs('꾸어어어어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정제(전처리) : 불필요한 형태소 제거, 단어 통일\n",
    "# 정규표현식을 이용 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A=np.array([[0,0,0,1,0,1,1,0,0],\n",
    "            [0,0,0,1,1,0,1,0,0],\n",
    "            [0,1,1,0,2,0,0,0,0],\n",
    "            [1,0,0,0,0,0,0,1,1]])\n",
    "A.shape\n",
    "\n",
    "U, s, VT=np.linalg.svd(A, full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.69, 2.05, 1.73, 0.77])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.round(2) # 직교행렬\n",
    "s.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.69, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 2.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.73, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.77, 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S=np.zeros((4,9))\n",
    "S[:4,:4]=np.diag(s)\n",
    "S.round(2) # 특이값 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.  , -0.31, -0.31, -0.28, -0.8 , -0.09, -0.28, -0.  , -0.  ],\n",
       "       [ 0.  , -0.24, -0.24,  0.58, -0.26,  0.37,  0.58, -0.  , -0.  ],\n",
       "       [ 0.58, -0.  ,  0.  ,  0.  , -0.  ,  0.  , -0.  ,  0.58,  0.58],\n",
       "       [ 0.  , -0.35, -0.35,  0.16,  0.25, -0.8 ,  0.16, -0.  , -0.  ],\n",
       "       [-0.  , -0.78, -0.01, -0.2 ,  0.4 ,  0.4 , -0.2 ,  0.  ,  0.  ],\n",
       "       [-0.29,  0.31, -0.78, -0.24,  0.23,  0.23,  0.01,  0.14,  0.14],\n",
       "       [-0.29, -0.1 ,  0.26, -0.59, -0.08, -0.08,  0.66,  0.14,  0.14],\n",
       "       [-0.5 , -0.06,  0.15,  0.24, -0.05, -0.05, -0.19,  0.75, -0.25],\n",
       "       [-0.5 , -0.06,  0.15,  0.24, -0.05, -0.05, -0.19, -0.25,  0.75]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A,np.dot(np.dot(U,S),VT).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.69 0.  ]\n",
      " [0.   2.05]]\n"
     ]
    }
   ],
   "source": [
    "# 절단된(truncated) SVD\n",
    "# 토픽 2개\n",
    "S=S[:2,:2]\n",
    "print(S.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24,  0.75],\n",
       "       [-0.51,  0.44],\n",
       "       [-0.83, -0.49],\n",
       "       [-0.  , -0.  ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape # 4,4\n",
    "U=U[:,:2] # 4,2\n",
    "# U의 의미는 4개 문서 각각에 대한 잠재된 의미를 표현하고 있는 수치 문서 벡터\n",
    "U.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.  , -0.31, -0.31, -0.28, -0.8 , -0.09, -0.28, -0.  , -0.  ],\n",
       "       [ 0.  , -0.24, -0.24,  0.58, -0.26,  0.37,  0.58, -0.  , -0.  ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT.shape # 9,9\n",
    "VT=VT[:2,:] # 2,9 => 토픽 * 단어개수\n",
    "# VT 각 열은 잠재 의미를 나타내기 위한 수치화된 단어 벡터\n",
    "VT.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]\n",
      " [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]\n",
      " [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.   -0.    0.    0.    0.  ]]\n",
      "[[0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "Aprime=np.dot(np.dot(U,S),VT).round(2)\n",
    "print(Aprime)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.  , -0.83, -0.83, -0.75, -2.16, -0.24, -0.75, -0.  , -0.  ],\n",
       "       [ 0.  , -0.49, -0.49,  1.2 , -0.53,  0.75,  1.2 , -0.  , -0.  ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(S,VT).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "           돈   사랑   저는    좋아요\n",
    "줄거리 1   0    1      1       1\n",
    "줄거리 2   1    0      1       1 \n",
    "줄거리 3   2    0      2       2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov1=np.array([0,1,1,1])\n",
    "mov2=np.array([1,0,1,1])\n",
    "mov3=np.array([2,0,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667\n",
      "1.0000000000000002\n",
      "0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "np.dot(mov1,mov2) # 두 벡터의 내적\n",
    "np.dot(mov1,mov2)/(norm(mov1)*norm(mov2))\n",
    "\n",
    "def cos_sim(X,Y):\n",
    "    return np.dot(X,Y)/(norm(X)*norm(Y))\n",
    "\n",
    "print(cos_sim(mov1,mov2))\n",
    "print(cos_sim(mov2,mov3))\n",
    "print(cos_sim(mov1,mov3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(\"the-movies-dataset/movies_metadata.csv\")\n",
    "data=data.head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jumanji'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['overview'].isnull()\n",
    "data['overview'].fillna('',inplace=True)\n",
    "data['title'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer(stop_words='english')\n",
    "tfidf_mat = tfidf.fit_transform(data['overview']) # tf-idf matrix 생성\n",
    "tfidf_mat = tfidf_mat.toarray() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToyStory=tfidf_mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['The 40 Year Old Virgin', 0.2795541150488133],\n",
       " ['Malice', 0.1375106791269381],\n",
       " ['For Love or Money', 0.11656473849605975],\n",
       " ['Window to Paris', 0.06547657266141106],\n",
       " ['Mute Witness', 0.06397135942434755],\n",
       " ['Safe Passage', 0.04526684118307106],\n",
       " ['Carried Away', 0.04369986367616119],\n",
       " ['Four Rooms', 0.04113995020790759],\n",
       " ['Pretty Woman', 0.040530287641558756],\n",
       " ['Much Ado About Nothing', 0.03869944498425505]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cos_sim(X,Y):\n",
    "    return np.dot(X,Y)/(norm(X)*norm(Y))\n",
    "\n",
    "def similar_toystory(data, ToyStory, tfidf_mat):\n",
    "    movie_list=[]\n",
    "    for i in range(1, tfidf_mat.shape[0]):\n",
    "        cos=cos_sim(ToyStory,tfidf_mat[i])\n",
    "        movie_list.append([data['title'][i],cos])\n",
    "    movie_list=sorted(movie_list, key=lambda s:s[1], reverse=True)\n",
    "    \n",
    "    return movie_list[:10]\n",
    "\n",
    "similar_toystory(data, ToyStory,tfidf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(nan, 19909), (0.018138871622511377, 19916), (0.019853155734699927, 19969), (0.024584793469282384, 19997), (0.027105644611392515, 19970), (0.0524938793119962, 17646), (0.06099673588133421, 19993), (0.06369332191395058, 18061), (0.07448744944250994, 19876), (0.11798196632714826, 19977)]\n"
     ]
    }
   ],
   "source": [
    "a=similar_toystory(tfidf_mat)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toy Story'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
