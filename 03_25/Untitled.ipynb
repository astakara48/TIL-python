{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구현\n",
    "# 1. 초기화(입력, 은닉, 출력 노드의 수 설정)\n",
    "# 2. 학습(가중치 업데이트)\n",
    "# 3. 질의(입력 -> 연산 -> 출력 노트에 전달)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class neuralNetwork:\n",
    "    \n",
    "    # 신경망 초기화 기능\n",
    "    # 입력, 은닉, 출력 계층에서 각 노드의 개수를 몇개로 할지 정해야함\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        self.inodes=input_nodes\n",
    "        self.hnodes=hidden_nodes\n",
    "        self.onodes=output_nodes\n",
    "        self.lr=learning_rate\n",
    "        \n",
    "    # 가중치는 행렬로 표현        \n",
    "    # 입력/은닉 사이 가중치 행렬 형식 : (은닉노드 * 입력노드 )\n",
    "    # 은닉/출력 사이 가중치 행렬 형식 : (출력노드 * 은닉노드 )\n",
    "\n",
    "    # 입력, 은닝 계층 사이의 가중치 행렬\n",
    "        self.wih=np.random.normal(0.0, pow(self.hnodes,-0.5), (self.hnodes,self.inodes))\n",
    "        # normal(평균, 표준편차, 개수)\n",
    "        \n",
    "        self.who=np.random.normal(0.0, pow(self.onodes,-0.5), (self.onodes,self.hnodes))\n",
    "\n",
    "        self.activation_function=lambda x:scipy.special.expit(x) # sigmoid\n",
    "        \n",
    "    # 신경망 학습 기능(2단계)\n",
    "    # 1단계(forward propagation) : 입력 데이터에 대해서 계산(query)\n",
    "    # 2단계(backward propagation) : 예측값과 실제값의 차이를 계산 -> 가중치 update\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs=np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        targets=np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs=np.dot(self.wih,inputs)\n",
    "        \n",
    "        hidden_outputs=self.activation_function(hidden_inputs)\n",
    "        \n",
    "        final_inputs=np.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        final_outputs=self.activation_function(final_inputs)\n",
    "        \n",
    "        output_errors=targets-final_outputs\n",
    "        # 오차 = 실제값 - 예측값\n",
    "        \n",
    "        # 은닉 계층 노드에 대한 역전파된 오차\n",
    "        # 은닉 계층의 오차는 가중치에 의해 나온다\n",
    "        # 출력 계층의 오차들을 재조합하여 계산한다.\n",
    "        hidden_errors=np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # 은닉 계층과 출력 계층 간의 가중치 업데이트(who)\n",
    "        self.who+=self.lr*np.dot((output_errors*final_outputs*(1.0-final_outputs)), np.transpose(hidden_outputs))\n",
    "        self.wih+=self.lr*np.dot((hidden_errors*hidden_outputs*(1.0-hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "    \n",
    "    #신경망 질의 기능 : 신경망으로 들어오는 입력을 받아 출력을 반환하는 함수\n",
    "    def query(self, inputs_list):\n",
    "        # 입력리스트를 2차워 행렬로 변환\n",
    "        inputs=np.array(inputs_list, ndmin=2).T\n",
    "        # 은닉계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs=np.dot(self.wih,inputs)\n",
    "        # 은닉계층에서 나가는 신호 계산\n",
    "        hidden_outputs=self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # 출력계층으로 들어오는 신호를 계산\n",
    "        final_inputs=np.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # 출력계층으로 나가는 신호를 계산\n",
    "        final_outputs=self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7517224 ],\n",
       "       [0.49630417],\n",
       "       [0.3526509 ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 노드수 설정\n",
    "input_nodes=3\n",
    "hidden_nodes=3\n",
    "output_nodes=3\n",
    "\n",
    "# 학습률 정의 (0.1~0.01)\n",
    "learning_rate=0.3\n",
    "\n",
    "# 신경망 클래스 객체를 생성\n",
    "n=neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "n.query([1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3],ndmin=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
